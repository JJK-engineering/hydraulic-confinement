{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# procedure for calculating hydraulic confinement along a pressure tunnel \n",
    "#  calculation done at stationed points at a selected interval along tunnel alignment\n",
    "#  calculation determines the minimum dstance from the stationed point to the terrain surface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # python setup for qgis processing (based on TunnelGIS configuration)\n",
    "# ##import sys\n",
    "# from qgis.core import *\n",
    "# from PyQt4.QtGui import *\n",
    "\n",
    "# app = QApplication([], True)\n",
    "# QgsApplication.setPrefixPath(\"/usr\", True)\n",
    "# QgsApplication.initQgis()\n",
    "\n",
    "# sys.path.append('/usr/share/qgis/python/plugins')\n",
    "# from processing.core.Processing import Processing\n",
    "# Processing.initialize()\n",
    "# from processing.tools import *\n",
    "\n",
    "# import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required python libraires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import geopandas as gpd\n",
    "import shapely as sp\n",
    "import os \n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set wd for this procedure \n",
    "os.chdir(\"/home/kaelin_joseph/DSS.HydraulicConfinement/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gpd version\n",
    "gpd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pd version\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define required input files\n",
    "DTM = \"data/swissALTI3D_.tif\"  #DEM with surface topography\n",
    "Alignment = \"data/TestAlignment.p0.csv\"  #tunnel alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temporary data\n",
    "Alignment_SHP ='tmp/TestAlignment.shp'  #alignment shp from Alignment\n",
    "Alignment_grass = 'tmp/TestAlignmentGrass.csv'  #alignment csv fixed for grass\n",
    "Alignment_line = \"tmp/TestAlignmentLine.shp\"  #intermediate data\n",
    "#Alignment_points = \"tmp/TestAlignmentPoints.shp\"  #alignment containing station points\n",
    "Alignment_points = \"tmp/Line_Point.csv\"  #alignment containing station points\n",
    "Alignment_DTM = \"tmp/TestAlignmentDTM.csv\"  #alignment including terrain elevations at station points\n",
    "Buffer_SHP = \"tmp/TestBuffer.shp\"  #buffer shp containing ring grid points at a particular station point\n",
    "Test_buffer_csv = \"tmp/TestBuffer.csv\"  #buffer written to csv\n",
    "Test_buffer_csv = \"tmp/TestBuffer.csv\"  #buffer written to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create alignment_df (dataframe) from alignment csv                         #ToDo JK: make into csv -> df function\n",
    "#   required alignment input data: x_align, y_align, z_align at alignment definition points\n",
    "#   check csv data before creating df (no trailing blank lines, no duplicate lines)\n",
    "alignment_df = pd.read_csv(Alignment)\n",
    "# delete row if only NA are present in row\n",
    "alignment_df = alignment_df.dropna(how = \"all\")\n",
    "# round alignment_df to three decimals\n",
    "alignment_df = alignment_df.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create alignment_df (dataframe) from alignment csv                         #ToDo JK: make into csv -> df function\n",
    "#   required alignment input data: x_align, y_align, z_align at alignment definition points\n",
    "#   check csv data before creating df (no trailing blank lines, no duplicate lines)\n",
    "alignment_points_df = pd.read_csv(Alignment_points)\n",
    "# delete row if only NA are present in row\n",
    "alignment_points_df = alignment_points_df.dropna(how = \"all\")\n",
    "# round alignment_df to three decimals\n",
    "alignment_points_df = alignment_points_df.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variable \"ID\" to alignment_points_df\n",
    "alignment_points_df[\"ID\"] = alignment_points_df.index\n",
    "alignment_points_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create segmented polyline representing alignment from points in alignment_df\n",
    "# #   grass input for function v.in.line 1) nust have x first and y second; 2) no header \n",
    "# #   required output data: x_align, y_align at each station point            #ToDo JK: make into stationing function\n",
    "# alignment_df_grass = alignment_df.loc[:,[\"Easting\", \"Northing\"]]  #x first and y second\n",
    "# alignment_df_grass.to_csv(Alignment_grass, header=False, index=False)  #no header\n",
    "\n",
    "# # points to line\n",
    "# processing.runalg(\"grass7:v.in.lines\",Alignment_grass,\",\",False,\n",
    "#                   \"2605158.67928,2621471.50192,1265877.44552,1269377.45567\",0,Alignment_line)\n",
    "\n",
    "# # line to station points\n",
    "# processing.runalg(\"grass7:v.to.points\",Alignment_line,\"100\",1,True,\n",
    "#                   \"2603510,2624270,1260650,1274890\",-1,0.0001,0,Alignment_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create alignment_SHP from alignment_df for checking                       #ToDo JK: make into df -> shp function\n",
    "# alignment_spatial_points = [sp.geometry.Point(row['Easting'], row['Northing'])\n",
    "#                             for key, row in alignment_df.iterrows()]\n",
    "# alignment_crs = {'init': 'epsg:2056'}  #define crs\n",
    "# alignment_spatial = gpd.GeoDataFrame(alignment_df, geometry=alignment_spatial_points, crs = alignment_crs)\n",
    "# alignment_spatial.to_file(Alignment_SHP, driver='ESRI Shapefile') \n",
    "\n",
    "# #print(alignment_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # plot alignment for checking\n",
    "# #   reference: http://nbviewer.jupyter.org/gist/perrygeo/c426355e40037c452434\n",
    "# pylab.rcParams['figure.figsize'] = 13.5, 9\n",
    "\n",
    "# # get data to plot\n",
    "# line = gpd.GeoDataFrame.from_file(Alignment_line)\n",
    "# point1 = gpd.GeoDataFrame.from_file(Alignment_SHP)\n",
    "# point2 = gpd.GeoDataFrame.from_file(Alignment_points)\n",
    "\n",
    "# # plot\n",
    "# base = line.plot(color='black')\n",
    "# point1.plot(ax=base, marker='o', color='red', markersize=10,  markeredgewidth=0.0);\n",
    "# point2.plot(ax=base, marker='*', color='blue', markersize=10, markeredgewidth=0.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create alignment_points_df from Alignment_points shp                       #ToDo JK: make into shp -> df function\n",
    "# #   required output data: id_align, x_align, y_align at each station point\n",
    "# fp = Alignment_points\n",
    "# alignment_points_df = gpd.read_file(fp)\n",
    "# #type(alignment_points_df)\n",
    "# #alignment_points_df.head()\n",
    "\n",
    "# # create columns for Easting and Northing, then delete columns cat_ and geometry                          #ToDo KLK\n",
    "\n",
    "# alignment_points_df.geometry\n",
    "# #alignment_points_df.apply(lambda p: p.x)\n",
    "# #alignment_points_df.apply(lambda p: p.y)\n",
    "\n",
    "# alignment_points_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s = gpd.GeoSeries([Point(4.42, 50.4), Point(4.43, 50.2)])\n",
    "# s.apply(lambda p: p.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interpolate alignment elevations at all station points and write to alignment_points_df                 #ToDo KLK\n",
    "#   join alignment_points_df with alignment_df\n",
    "#   required output data: z_align at each station point                #ToDo JK: make into z interpolation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variable \"Distance_alignment\" to alignment_df\n",
    "\n",
    "alignment_df[\"Distance_alignment\"] = np.nan\n",
    "\n",
    "for n in range(0, len(alignment_df)-1): # why len(alignment_d -1? Because the distance cannot be calculated for the last point\n",
    "    #print (n)\n",
    "    alignment_df.iloc[n, alignment_df.columns.get_loc(\"Distance_alignment\")] = ((alignment_df.iloc[n+1][\"Easting\"]-alignment_df.iloc[n][\"Easting\"])**2 +(alignment_df.iloc[n+1][\"Northing\"]-alignment_df.iloc[n][\"Northing\"])**2 )**(0.5)\n",
    "\n",
    "alignment_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variable \"Distance_station\" to alignment_points_df\n",
    "alignment_points_df[\"Distance_station\"] = np.nan\n",
    "\n",
    "for n in range(0, len(alignment_points_df)-1): # why len(alignment_d -1? Because the distance cannot be calculated for the last point\n",
    "    #print(n)\n",
    "    alignment_points_df.iloc[n, alignment_points_df.columns.get_loc(\"Distance_station\")] = ((alignment_points_df.iloc[n+1][\"X\"]-alignment_points_df.iloc[n][\"X\"])**2 +(alignment_points_df.iloc[n+1][\"Y\"]-alignment_points_df.iloc[n][\"Y\"])**2 )**(0.5)\n",
    "\n",
    "alignment_points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variable \"Distance_station_sum\" to alignment_points_df\n",
    "alignment_points_df[\"Distance_station_sum\"] = np.nan\n",
    "\n",
    "for n in range(0, len(alignment_points_df)-1): # why len(alignment_d -1? Because the distance cannot be calculated for the last point\n",
    "    id_sel2 = alignment_points_df.loc[(alignment_points_df.ID.isin(range(0,n+1))), \"Distance_station\"] \n",
    "    id_sel2= id_sel2.tolist()\n",
    "    alignment_points_df.iloc[n, alignment_points_df.columns.get_loc(\"Distance_station_sum\")] = sum(id_sel2)\n",
    "\n",
    "alignment_points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join alignment_df to alignment_points_df\n",
    "alignment_points_df = pd.merge(left= alignment_points_df, right = alignment_df, \n",
    "                 left_on = [\"X\",\"Y\"], \n",
    "                 right_on = [\"Easting\",\"Northing\"], how = \"left\")\n",
    "\n",
    "alignment_points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up alignment_points_df\n",
    "alignment_points_df = alignment_points_df.drop(columns =[\"cat_\", \"Unnamed: 3\", \"Point\", \"Type\", \"Northing\", \"Easting\"])\n",
    "alignment_points_df.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ID of alignment_points_df where points of alignment_points_df == alignment_df\n",
    "id_sel =  alignment_points_df.loc[(alignment_points_df.Elevation.isin(alignment_df[\"Elevation\"])), \"ID\"] \n",
    "#alignment_points_df.loc[(alignment_points_df[\"Elevation\"] == alignment_df[\"Elevation\"][2]), \"ID\"] \n",
    "id_sel= id_sel.tolist()\n",
    "id_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in \"Elevation\" and \"Distance_alignment\" for points of alignment_points_df where points of \n",
    "# alignment_points_df != alignment_df\n",
    "# Maybe this step can be left out\n",
    "\n",
    "for n in range(0, len(id_sel)-1): \n",
    "    alignment_points_df.loc[(alignment_points_df.ID.isin(range(id_sel[n]+1, id_sel[n+1]))), \"Elevation\"] = alignment_df[\"Elevation\"][n]\n",
    "alignment_points_df\n",
    "\n",
    "for n in range(0, len(id_sel)-1): \n",
    "    alignment_points_df.loc[(alignment_points_df.ID.isin(range(id_sel[n]+1, id_sel[n+1]))), \"Distance_alignment\"] = alignment_df[\"Distance_alignment\"][n]\n",
    "alignment_points_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variable \"Distance_station_sum2\" to alignment_points_df\n",
    "\n",
    "alignment_points_df[\"Distance_station_sum2\"] = np.nan\n",
    "\n",
    "for n in range(1, len(id_sel)-1): \n",
    "    alignment_points_df.loc[(alignment_points_df.ID.isin(range(id_sel[n], id_sel[n+1]))), \"Distance_station_sum2\"] = alignment_points_df[\"Distance_station_sum\"] - alignment_df[\"Distance_alignment\"][n-1]\n",
    "\n",
    "for n in range(0, 1): \n",
    "    alignment_points_df.loc[(alignment_points_df.ID.isin(range(id_sel[n], id_sel[n+1]))), \"Distance_station_sum2\"] =  alignment_points_df[\"Distance_station_sum\"]\n",
    "    \n",
    "alignment_points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i:', 2)\n",
      "[0, 1, 2, 5, 43]\n",
      "('m:', 3)\n",
      "('n:', 5)\n",
      "('o:', 1)\n",
      "('p:', 1)\n",
      "('Elevation n:', 253.058)\n",
      "('Elevation n:', 270.962)\n",
      "\n",
      "\n",
      "('i:', 3)\n",
      "[0, 1, 3, 5, 43]\n",
      "('m:', 3)\n",
      "('n:', 5)\n",
      "('o:', 1)\n",
      "('p:', 1)\n",
      "('Elevation n:', 253.058)\n",
      "('Elevation n:', 270.962)\n",
      "\n",
      "\n",
      "('i:', 4)\n",
      "[0, 1, 4, 5, 43]\n",
      "('m:', 3)\n",
      "('n:', 5)\n",
      "('o:', 1)\n",
      "('p:', 1)\n",
      "('Elevation n:', 253.058)\n",
      "('Elevation n:', 270.962)\n",
      "\n",
      "\n",
      "('i:', 6)\n",
      "[0, 1, 5, 6, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 7)\n",
      "[0, 1, 5, 7, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 8)\n",
      "[0, 1, 5, 8, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 9)\n",
      "[0, 1, 5, 9, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 10)\n",
      "[0, 1, 5, 10, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 11)\n",
      "[0, 1, 5, 11, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 12)\n",
      "[0, 1, 5, 12, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 13)\n",
      "[0, 1, 5, 13, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 14)\n",
      "[0, 1, 5, 14, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 15)\n",
      "[0, 1, 5, 15, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 16)\n",
      "[0, 1, 5, 16, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 17)\n",
      "[0, 1, 5, 17, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 18)\n",
      "[0, 1, 5, 18, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 19)\n",
      "[0, 1, 5, 19, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 20)\n",
      "[0, 1, 5, 20, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 21)\n",
      "[0, 1, 5, 21, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 22)\n",
      "[0, 1, 5, 22, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 23)\n",
      "[0, 1, 5, 23, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 24)\n",
      "[0, 1, 5, 24, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 25)\n",
      "[0, 1, 5, 25, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 26)\n",
      "[0, 1, 5, 26, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 27)\n",
      "[0, 1, 5, 27, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 28)\n",
      "[0, 1, 5, 28, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 29)\n",
      "[0, 1, 5, 29, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 30)\n",
      "[0, 1, 5, 30, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 31)\n",
      "[0, 1, 5, 31, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 32)\n",
      "[0, 1, 5, 32, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 33)\n",
      "[0, 1, 5, 33, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 34)\n",
      "[0, 1, 5, 34, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 35)\n",
      "[0, 1, 5, 35, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 36)\n",
      "[0, 1, 5, 36, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 37)\n",
      "[0, 1, 5, 37, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 38)\n",
      "[0, 1, 5, 38, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 39)\n",
      "[0, 1, 5, 39, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 40)\n",
      "[0, 1, 5, 40, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 41)\n",
      "[0, 1, 5, 41, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n",
      "('i:', 42)\n",
      "[0, 1, 5, 42, 43]\n",
      "('m:', 4)\n",
      "('n:', 43)\n",
      "('o:', 2)\n",
      "('p:', 5)\n",
      "('Elevation n:', 268.579)\n",
      "('Elevation n:', 253.058)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add variable \"Z\" to alignment_points_df\n",
    "\n",
    "\n",
    "alignment_points_df[\"Z\"] = np.nan\n",
    "\n",
    "for i in range(0, len(alignment_points_df)): # why len(alignment_d -1? Because the distance cannot be calculated for the last point\n",
    "    if i in id_sel:\n",
    "        alignment_points_df.iloc[i, alignment_points_df.columns.get_loc(\"Z\")] = alignment_points_df.iloc[i][\"Elevation\"]\n",
    "\n",
    "    else:\n",
    "        \n",
    "        id_sel2 = id_sel\n",
    "        id_sel2.append(i)\n",
    "        id_sel2.sort()\n",
    "        \n",
    "        m = id_sel2.index(i)+1     \n",
    "        n = id_sel2[m]  \n",
    "        o = id_sel2.index(i)-1\n",
    "        p = id_sel2[o]\n",
    "        \n",
    "        alignment_points_df.iloc[i, alignment_points_df.columns.get_loc(\"Z\")] = alignment_points_df.iloc[p][\"Elevation\"]+(alignment_points_df.iloc[n][\"Elevation\"]-alignment_points_df.iloc[p][\"Elevation\"])/alignment_points_df.iloc[i][\"Distance_alignment\"]*alignment_points_df.iloc[i-1][\"Distance_station_sum2\"]\n",
    "    \n",
    "#         print(\"i:\",i)\n",
    "#         print(id_sel2)\n",
    "#         print(\"m:\", m)\n",
    "#         print(\"n:\",n)\n",
    "#         print(\"o:\", o)\n",
    "#         print(\"p:\",p)\n",
    "#         print(\"Elevation n:\",alignment_points_df.iloc[n][\"Elevation\"])\n",
    "#         #print(\"Elevation Test:\"alignment_df.loc[(alignment_df[\"ID\"] == o), \"Elevation\"]) # maybe above mentioned code can be replaced through this\n",
    "#         print(\"Elevation n:\",alignment_points_df.iloc[p][\"Elevation\"])\n",
    "#         print(\"\\n\")\n",
    "        \n",
    "        id_sel2.remove(i)\n",
    "\n",
    "#alignment_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alignment_points_df to spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grass7:r.what.points to get DTM value for z for points along alignment and write to .csv file\n",
    "                                                                             #ToDo JK: make into what.points function\n",
    "\n",
    "# alignment_points_df to alignment_points_shp\n",
    "\n",
    "# processing.runalg(                                                       \n",
    "#                   \"grass7:r.what.points\",DTM,alignment_points_shp,\n",
    "#                   \"NA\",\",\",500,True,False,False,False,False,\n",
    "#                   \"2603510.0,2624270.0,1260650.0,1274890.0\",-1,0.0001,Alignment_DTM\n",
    "#                  )\n",
    "# #out = open(Alignment_DTM, 'r')\n",
    "# #print(out.read())  #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read Alignment_DTM csv and write to alignment_points_df             #ToDo JK: reuse function csv -> df from above\n",
    "#   required output data: z_dtm at each station point\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # prepare circular grid as buffer around a station point and determine minimal distance to terrain surface \n",
    "# #   this calculation is defined as a function, to be applied at each station point\n",
    "# #   inputs are easting, northing, overburden at stationed point (and a coeff for buffer_radius = coeff*cover) \n",
    "\n",
    "# # input data  #temporarily static\n",
    "# point = np.array([2612060, 1268065])  #station point [from alignment_points_df]\n",
    "# h = 110.0  #overburden depth above station point [calculate from alignment_points_df]\n",
    "\n",
    "# def make_buffer(point, overburden):\n",
    "#     c = 0.5  #buffer radius = c*h\n",
    "#     res = 20.0  #nominal grid resolution \n",
    "#     intvls_r = int(h*c / res)  #number of intervals along the buffer radius, close enough\n",
    "#     res_r = h*c / intvls_r  #effective resolution along the radius\n",
    "#     buffer = np.array(point)  #initialize buffer, first item is exactly at station point\n",
    "#     print(\"buffer: \"+str(buffer))\n",
    "\n",
    "#     # calculate local coordinates for grid along a ring\n",
    "#     for i in range(intvls_r):\n",
    "#         r = c*h - i*res_r\n",
    "#         perim = 2 * r * pi \n",
    "#         intvls_c = int(perim/res)  #number of intervals along a ring, close enough\n",
    "#         item = np.array([0.0, 0.0])  #initialize\n",
    "#         for j in range(intvls_c):\n",
    "#             item[0] = (sin((2*pi) / intvls_c *(j+1)) *r) + point[0]\n",
    "#             item[1] = (cos((2*pi) / intvls_c *(j+1)) *r) + point[1]\n",
    "#             buffer = np.vstack((buffer, item))  #vstack works with arrays of diff nr of items, append does not        \n",
    "\n",
    "#         print(\"r: \"+str(r))\n",
    "#         print(\"intvls_r: \"+str(intvls_r))\n",
    "#         print(\"intvls_c: \"+str(intvls_c))\n",
    "#         return buffer\n",
    "        \n",
    "# buffer = make_buffer(point=point, overburden=h)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # use make_buffer to get buffer grid points at all station points along alignment                         #ToDo KLK\n",
    "# #   write buffer points to buffer_df and to alignment_points_df\n",
    "# #   required output data: id_align, id_buffer, x_buffer, y_buffer, z_dtm at each buffer point  \n",
    "\n",
    "# # temporary code for handling one buffer\n",
    "# # create Buffer_SHP for grass from buffer\n",
    "# crs = {'init': 'epsg:2056'}  #define crs\n",
    "\n",
    "# buffer_df = pd.DataFrame.from_records(data=buffer, columns=['Easting', 'Northing'], index=None)\n",
    "# #buffer_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create shp file with all buffer points                                         #ToDo JK: reuse df -> shp function\n",
    "# buffer_points = [sp.geometry.Point(row['Easting'], row['Northing'])\n",
    "#                  for key, row in buffer_df.iterrows()]\n",
    "# #len(buffer_points)  #check\n",
    "\n",
    "# # write buffer to Buffer_SHP as shape file\n",
    "# buffer_spatial = gpd.GeoDataFrame(buffer_df, geometry=buffer_points, crs = crs)\n",
    "# buffer_spatial.to_file(Buffer_SHP, driver='ESRI Shapefile') \n",
    "# #print(buffer_spatial)  #check\n",
    "# print(Buffer_SHP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # use grass7:r.what.points to read Buffer_SHP to get z_dtm at each buffer point for all station points\n",
    "\n",
    "# # temporary code for handling one buffer\n",
    "# # use grass7:r.what.points to read Buffer_SHP to get z_dtm at each point\n",
    "# test_buffer_csv = \"tmp/test_buffer.csv\"\n",
    "# # buffer_SHP = {'init': 'epsg:2056'}  #define crs\n",
    "# processing.runalg(\"grass7:r.what.points\",DTM,Buffer_SHP,            #ToDo JK: reuse what.points function from above\n",
    "#                   \"NA\",\",\",500,True,False,False,False,False,\n",
    "#                   \"2603510.0,2624270.0,1260650.0,1274890.0\",-1,0.0001,test_buffer_csv\n",
    "#                  )\n",
    "\n",
    "# out = open(test_buffer_csv, 'r')\n",
    "# print(out.read())  #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read buffer points from Test_buffer_csv into alignment_points_df\n",
    "#   required output data: id_align, id_buffer, x_buffer, y_buffer, z_dtm at each buffer point  \n",
    "                                                                      #ToDo JK: reuse function csv -> df from above\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate minimum distance to terrain in each buffer ring\n",
    "#   required output data: dist for each buffer point, min_dist for buffer ring\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate hydraulic confinement safety factor at each station point\n",
    "#   required input data: reference maximum water pressure elevation (static or dynamic ??) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot results for hydraulic confinement safety factor as horizontal bar beneath longitudinal profile \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
