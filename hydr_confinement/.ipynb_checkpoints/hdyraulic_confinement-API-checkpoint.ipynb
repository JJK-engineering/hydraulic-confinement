{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# procedure for calculating hydraulic confinement along a pressure tunnel \n",
    "#   safety factor against hydraulic confinement calculated at stationed points along tunnel alignment\n",
    "#   calculation determines the minimum dstance from the stationed point to the terrain surface \n",
    "# API work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set-up must be adjusted for use in Flask Server (see Notes for Flask Server and Flask code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up environ\n",
    "import sys, os\n",
    "# set wd for this procedure and project \n",
    "#  ToDo: read in a key to set working dir (with root set from sys config)\n",
    "os.chdir(\"/home/kaelin_joseph/DSS.HydraulicConfinement/\")\n",
    "os.environ[\"DISPLAY\"] = \":1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import required python libraires\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python setup for qgis processing\n",
    "from qgis.core import QgsApplication\n",
    "from PyQt4.QtGui import QApplication\n",
    "app = QApplication([], True)  #True -> window display enabled\n",
    "QgsApplication.setPrefixPath(\"/usr\", True)\n",
    "QgsApplication.initQgis()\n",
    "sys.path.append('/usr/share/qgis/python/plugins')  #export PYTHONPATH not needed in start script\n",
    "from processing.core.Processing import Processing\n",
    "Processing.initialize() \n",
    "import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up plotly in 'offline' mode\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plotly\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# code below to be added to Flask hydraulic_confinement()\n",
    "# entire procedure is in function 'hydraulic_confinement()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define required input files\n",
    "DTM = \"data/in/NamAngTopogRaster.tif\"  #DEM with surface topography\n",
    "Alignment = \"data/in/NamAngAlignmentHRT.r1.csv\"  #tunnel alignment\n",
    "DTM_slope='data/in/NamAngTopogSlopeRaster.tif'  #DEM containing slope angle as attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define required input data\n",
    "# mapping\n",
    "crs = {'init': 'epsg:32648'}  #define crs for project\n",
    "grass_region = \"726000,729500,1670500,1674000\"  #map region E1,E2,N1,N2\n",
    "# resolution for analysis\n",
    "grass_station_dist = 50  #use for low resolution\n",
    "c = 0.5  #ring buffer radius = c*h  (h=overburden)\n",
    "res = 25.0  #use for low resolution\n",
    "# rock properties\n",
    "#  ToDo: mv to calling parameter (how to handle multiple rock layers?)\n",
    "density_rock = 28.0  #kN/m3\n",
    "# hydraulic properties\n",
    "#  ToDo: mv to calling parameter\n",
    "max_static_water_level = 637.20 #MASL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define temporary data\n",
    "Alignment_shp ='tmp/NamAngAlignment.shp'  #alignment shp from Alignment\n",
    "Alignment_grass_csv = 'tmp/NamAngAlignmentGrass.csv'  #alignment csv fixed for grass\n",
    "Alignment_line_shp = \"tmp/NamAngAlignmentLine.shp\"  #intermediate data\n",
    "Alignment_stationed_shp = \"tmp/NamAngAlignmentStationed.shp\"  #alignment shp containing station points\n",
    "Alignment_dtm_csv = \"tmp/NamAngAlignmentDTM.csv\"  #alignment including terrain elevations at station points\n",
    "Buffer_shp = \"tmp/NamAngBuffer.shp\"  #buffer shp containing ring grid points at a particular station point\n",
    "Buffer_all_csv = \"tmp/NamAngBufferAll.csv\"  # all station point ring buffers written to csv\n",
    "Buffer_all_shp = \"tmp/NamAngBufferFinal.shp\"\n",
    "Buffer_dtm_csv = \"tmp/NamAngBufferDTM.csv\"\n",
    "Buffer_slope_csv = \"tmp/NamAngBufferSlope.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignment = {\n",
    "    'Station':[\"0+000\",\"0+163.81\",\"2+063.77\",\"2+603.58\",\"3+030.73\"],\n",
    "    'Northing':[1673035.25,1673051.68,1672130.47,1671662.07,1671268.20],\n",
    "    'Easting':[726651.46,726815.60,728479.47,728758.97,728581.38],\n",
    "    'Elevation':[625.850,625.543,504.226,469.758,464.220]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignment_df = pd.DataFrame(alignment)\n",
    "alignment_df = alignment_df[['Station','Northing','Easting','Elevation']]  #for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'tmp/NamAngAlignmentStationed.shp'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create stationed alignment as Alignment_stationed_shp\n",
    "alignment_df_grass = alignment_df.loc[:,[\"Easting\", \"Northing\"]]  #x first and y second\n",
    "alignment_df_grass.to_csv(Alignment_grass_csv, header=False, index=False)  #no header\n",
    "# points to line, write output to Alignment_line_shp\n",
    "processing.runalg(\"grass7:v.in.lines\",Alignment_grass_csv,\",\",False,\n",
    "                  grass_region,0,Alignment_line_shp)  #no spaces between commas\n",
    "# line to station points, ouput segmented polyline to Alignment_stationed_shp\n",
    "processing.runalg(\"grass7:v.to.points\",Alignment_line_shp,grass_station_dist,1,True,\n",
    "                  grass_region,-1,0.0001,0,Alignment_stationed_shp)  #no spaces between commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create alignment_stationed_df from Alignment_stationed_shp\n",
    "alignment_stationed_df = gpd.read_file(Alignment_stationed_shp)\n",
    "# create columns for x_align, y_align, then delete columns cat_ and geometry\n",
    "alignment_stationed_df[\"x_align\"] = alignment_stationed_df.geometry.x\n",
    "alignment_stationed_df[\"y_align\"] = alignment_stationed_df.geometry.y\n",
    "alignment_stationed_df = alignment_stationed_df.drop(columns =[\"cat_\", \"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add required fields to alignment_stationed_df\n",
    "# add \"id\" \n",
    "alignment_stationed_df[\"id_point\"] = alignment_stationed_df.index\n",
    "# add \"distance_stat\" referencing length between point n and point n+1\n",
    "alignment_stationed_df[\"distance_stat\"] = np.nan\n",
    "for n in range(0, len(alignment_stationed_df)-1):\n",
    "    alignment_stationed_df.iloc[n, alignment_stationed_df.columns.get_loc(\"distance_stat\")] = (\n",
    "        ((alignment_stationed_df.iloc[n +1][\"x_align\"] - alignment_stationed_df.iloc[n][\"x_align\"])**2\n",
    "        +(alignment_stationed_df.iloc[n +1][\"y_align\"] \n",
    "        - alignment_stationed_df.iloc[n][\"y_align\"])**2 )**(0.5) )\n",
    "# add \"distance_stat_sum\"\n",
    "alignment_stationed_df[\"distance_stat_sum\"] = np.nan\n",
    "for n in range(0, len(alignment_stationed_df) -1):\n",
    "    distance = ( alignment_stationed_df.loc[(alignment_stationed_df.id_point.isin(range(0,n +1))), \n",
    "                        \"distance_stat\"] )\n",
    "    distances = distance.tolist()\n",
    "    alignment_stationed_df.iloc[n, alignment_stationed_df.columns.get_loc(\"distance_stat_sum\")] = (\n",
    "                                                                                        sum(distances) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add required field \"distance_intermed_align\" to alignment_df\n",
    "alignment_df[\"distance_intermed_align\"] = np.nan\n",
    "for n in range(0, len(alignment_df) -1):\n",
    "    alignment_df.iloc[n, alignment_df.columns.get_loc(\"distance_intermed_align\")] = (\n",
    "        ((alignment_df.iloc[n +1][\"Easting\"]-alignment_df.iloc[n][\"Easting\"])**2 \n",
    "             +(alignment_df.iloc[n +1][\"Northing\"]-alignment_df.iloc[n][\"Northing\"])**2 )**(0.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join alignment_df to alignment_stationed_df\n",
    "alignment_stationed_df = pd.merge(left= alignment_stationed_df, right = alignment_df, \n",
    "                 left_on = [\"x_align\",\"y_align\"], \n",
    "                 right_on = [\"Easting\",\"Northing\"], how = \"left\")\n",
    "# clean up alignment_stationed_df\n",
    "try:\n",
    "    alignment_stationed_df = (\n",
    "        alignment_stationed_df.drop(columns =[\"Point\", \"Type\", \"Northing\", \"Easting\"]) )\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get id_points for alignment points in alignment_stationed_df \n",
    "#   select points where Elevation of point not NaN\n",
    "id_points_align =  (\n",
    "    alignment_stationed_df.loc[(alignment_stationed_df.Elevation.isin(alignment_df[\"Elevation\"])), \n",
    "                                                                                   \"id_point\"] )\n",
    "id_points_align= id_points_align.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare intermediated data in alignment_stationed_df required to interpolate alignment elevations\n",
    "# fill in \"Elevation\" and \"distance_intermed_align\" for points in alignment_stationed_df \n",
    "#   where points of alignment_points_df != alignment_df\n",
    "# why is this needed??    ToDo: JK\n",
    "for n in range(0, len(id_points_align) -1): \n",
    "    alignment_stationed_df.loc[(alignment_stationed_df.id_point.isin(range(id_points_align[n] +1, \n",
    "                                id_points_align[n +1]))), \"Elevation\"] = ( \n",
    "                                                                    alignment_df[\"Elevation\"][n] )\n",
    "for n in range(0, len(id_points_align) -1): \n",
    "    alignment_stationed_df.loc[(alignment_stationed_df.id_point.isin(range(id_points_align[n] +1, \n",
    "                                id_points_align[n +1]))), \"distance_intermed_align\"] = ( \n",
    "                                                        alignment_df[\"distance_intermed_align\"][n] )\n",
    "# add \"distance_intermed_stat\" to alignment_stationed_df \n",
    "alignment_stationed_df[\"distance_intermed_stat\"] = np.nan\n",
    "for n in range(0, 1):\n",
    "    alignment_stationed_df.loc[(alignment_stationed_df.id_point.isin(range(id_points_align[n], \n",
    "                                id_points_align[n +1]))), \"distance_intermed_stat\"] =  ( \n",
    "                                                    alignment_stationed_df[\"distance_stat_sum\"] )\n",
    "for n in range(1, len(id_points_align) -1):\n",
    "      alignment_stationed_df.loc[(alignment_stationed_df.id_point.isin(range(id_points_align[n], \n",
    "                        id_points_align[n +1]))), \"distance_intermed_stat\"] = ( \n",
    "                                alignment_stationed_df[\"distance_stat_sum\"] - \n",
    "                                alignment_stationed_df[\"distance_stat_sum\"][id_points_align[n] -1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interpolate alignment elevation (\"z_align\") at all station points and write to alignment_stationed_df\n",
    "# add variable \"z_align\" to alignment_stationed_df\n",
    "alignment_stationed_df[\"z_align\"] = np.nan\n",
    "for i in range(0, len(alignment_stationed_df)):\n",
    "    # alignment points\n",
    "    if i in id_points_align:\n",
    "        alignment_stationed_df.iloc[i, alignment_stationed_df.columns.get_loc(\"z_align\")] = ( \n",
    "                                                        alignment_stationed_df.iloc[i][\"Elevation\"] )\n",
    "    # stationed points\n",
    "    else:\n",
    "        id_points_align_plus_point_n = id_points_align\n",
    "        id_points_align_plus_point_n.append(i)\n",
    "        id_points_align_plus_point_n.sort()\n",
    "        m = id_points_align_plus_point_n.index(i) +1  #index of point n +1 (next alignment point)\n",
    "        n = id_points_align_plus_point_n[m]  #id_point of next alignment point  \n",
    "        o = id_points_align_plus_point_n.index(i) -1  #index of point n -1 (previous alignment point)\n",
    "        p = id_points_align_plus_point_n[o]  #id_point of previous alignment point\n",
    "        \n",
    "        alignment_stationed_df.iloc[i, alignment_stationed_df.columns.get_loc(\"z_align\")] = ( \n",
    "                                            alignment_stationed_df.iloc[p][\"Elevation\"] \n",
    "                                            +(alignment_stationed_df.iloc[n][\"Elevation\"] \n",
    "                                            -alignment_stationed_df.iloc[p][\"Elevation\"]) \n",
    "                                            /alignment_stationed_df.iloc[i][\"distance_intermed_align\"]\n",
    "                                            *alignment_stationed_df.iloc[i-1][\"distance_intermed_stat\"] )\n",
    "        id_points_align_plus_point_n.remove(i)  #needed ??  #ToDo JK\n",
    "alignment_stationed_df = alignment_stationed_df.drop(columns = [\"distance_intermed_align\"])\n",
    "alignment_stationed_df = alignment_stationed_df.drop(columns = [\"distance_intermed_stat\"])\n",
    "alignment_stationed_df = alignment_stationed_df.drop(columns = [\"Elevation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add required field \"z_dtm_align\" to alignment_stationed_df \n",
    "# list of shapely geometry points\n",
    "alignment_stationed_geometry = ( \n",
    "    [sp.geometry.Point(row['x_align'], row['y_align']) for key, row in alignment_stationed_df.iterrows()] )\n",
    "# create alignment_stationed_geometry_df\n",
    "alignment_stationed_geometry_df = ( \n",
    "    gpd.GeoDataFrame(alignment_stationed_df, geometry=alignment_stationed_geometry, crs = crs) )\n",
    "# write df to Alignment_stationed_shp (overwrite file)\n",
    "alignment_stationed_geometry_df.to_file(Alignment_stationed_shp, driver='ESRI Shapefile') \n",
    "# get DTM values for alignment_points\n",
    "#   write to Alignment_dtm_csv\n",
    "processing.runalg(\"grass7:r.what.points\",DTM,Alignment_stationed_shp, \"NA\",\",\", 500,\n",
    "                  True,False,False,False,False,grass_region,-1,0.0001,Alignment_dtm_csv)\n",
    "# create alignment_dtm_df (dataframe) from Alignment_dtm_csv \n",
    "alignment_dtm_df = pd.read_csv(Alignment_dtm_csv)\n",
    "# rename col=tmp... to \"z_dtm_align\"\n",
    "alignment_dtm_df_col_tmp = [col for col in alignment_dtm_df.columns if 'tmp' in col]\n",
    "if len(alignment_dtm_df_col_tmp) != 1:\n",
    "    print \"Extraction of DTM col=tmp did not work properly for alignment. Please check\"\n",
    "    exit()\n",
    "alignment_dtm_df = alignment_dtm_df.rename(\n",
    "    columns= {alignment_dtm_df_col_tmp[0]: \"z_dtm_align\"})\n",
    "# write alignment_dtm_df[\"z_dtm_align\"] to alignment_stationed_df[\"z_dtm_align\"]\n",
    "alignment_stationed_df[\"z_dtm_align\"] = alignment_dtm_df[\"z_dtm_align\"]\n",
    "alignment_stationed_df = alignment_stationed_df.drop(columns = [\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add require field \"h\" to alignment_stationed_df = overburden depth above station point \n",
    "alignment_stationed_df[\"h\"] = alignment_stationed_df[\"z_dtm_align\"] - alignment_stationed_df[\"z_align\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define make_buffer to get buffer grid points at all station points along alignment\n",
    "def make_buffer(point, overburden, c, res):\n",
    "    h = overburden\n",
    "    if h < 0.0:\n",
    "        print \"Overburden is negative. Please check\"\n",
    "        exit()\n",
    "    intvls_r = max(int(h*c / res), 1)  #number of intervals along the buffer radius, close enough\n",
    "    res_r = h*c / intvls_r  #effective resolution along the radius\n",
    "    buffer = np.array(point)  #initialize buffer, first item is exactly at station point\n",
    "    # calculate local coordinates for grid along a ring and add to point coor\n",
    "    for i in range(intvls_r):\n",
    "        r = c*h - i*res_r\n",
    "        perim = 2 * r * pi \n",
    "        intvls_c = max(int(perim/res), 1)  #number of intervals along a ring, close enough\n",
    "        item = np.array([0.0, 0.0])  #initialize       \n",
    "        for j in range(intvls_c):\n",
    "            item[0] = (sin((2*pi) / intvls_c *(j+1)) *r) + point[0]\n",
    "            item[1] = (cos((2*pi) / intvls_c *(j+1)) *r) + point[1]\n",
    "            buffer = np.vstack((buffer, item))\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create csv file with all buffer points\n",
    "# point = alignment_stationed_xy\n",
    "# create alignment_stationed_xy from alignment_stationed_df with x,y of all station points\n",
    "alignment_stationed_xy = alignment_stationed_df.as_matrix(columns=['x_align','y_align'])\n",
    "# overburden = alignment_stationed_h\n",
    "alignment_stationed_h = alignment_stationed_df.as_matrix(columns=['h'])\n",
    "# initialize buffer_df, buffer_all_df, buffer_all\n",
    "buffer_all = {}\n",
    "buffer_df = pd.DataFrame(columns=[\"id_point\", \"x_align\", \"y_align\", \"z_align\", \"h\" ,\"x_buffer\", \"y_buffer\"])\n",
    "buffer_all_df = pd.DataFrame(columns=[\"id_point\", \"x_align\", \"y_align\", \"z_align\", \"h\",\"x_buffer\", \"y_buffer\"])\n",
    "for n in range(0, len(alignment_stationed_df)): \n",
    "    buffer_point = make_buffer(point=alignment_stationed_xy[n], overburden=alignment_stationed_h[n], \n",
    "                               c=c, res=res)\n",
    "    buffer_all[n] = buffer_df.copy(deep=False)  #copy of initialized buffer_df\n",
    "    buffer_all[n][\"id_point\"] = [n] * len(buffer_point)  #list with len(buffer_point) number of n values) \n",
    "    buffer_all[n][\"stat_sum\"] = (  #make stat_sum correct for point n\n",
    "        [alignment_stationed_df.iloc[n-1, alignment_stationed_df.columns.get_loc(\"distance_stat_sum\")]] \n",
    "                                            * len(buffer_point) ) \n",
    "    buffer_all[n][\"dist_stat\"] = (  #make stat_sum correct for point n\n",
    "        [alignment_stationed_df.iloc[n-1, alignment_stationed_df.columns.get_loc(\"distance_stat\")]] \n",
    "                                            * len(buffer_point) ) \n",
    "    buffer_all[n][\"x_align\"] = ( \n",
    "        [alignment_stationed_df.iloc[n, alignment_stationed_df.columns.get_loc(\"x_align\")]] \n",
    "                                            * len(buffer_point) )      \n",
    "    buffer_all[n][\"y_align\"] = ( \n",
    "        [alignment_stationed_df.iloc[n, alignment_stationed_df.columns.get_loc(\"y_align\")]] \n",
    "                                            * len(buffer_point) )      \n",
    "    buffer_all[n][\"z_align\"] = ( \n",
    "        [alignment_stationed_df.iloc[n, alignment_stationed_df.columns.get_loc(\"z_align\")]] \n",
    "                                            * len(buffer_point) )           \n",
    "    buffer_all[n][\"h\"] = ( \n",
    "        [alignment_stationed_df.iloc[n, alignment_stationed_df.columns.get_loc(\"h\")]] \n",
    "                                            * len(buffer_point) )           \n",
    "    buffer_all[n][\"x_buffer\"] = buffer_point[0:,0]\n",
    "    buffer_all[n][\"y_buffer\"] = buffer_point[0:,1]\n",
    "    buffer_all_df = pd.concat([buffer_all_df, buffer_all[n]])\n",
    "# add variable \"id_buffer_point\" to buffer_all_df\n",
    "buffer_all_df = buffer_all_df.reset_index(drop=True)\n",
    "buffer_all_df[\"id_buffer_point\"] = buffer_all_df.index    \n",
    "# save buffer_all_df to csv\n",
    "buffer_all_df.to_csv(Buffer_all_csv, sep=\",\", na_rep=\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add required field \"z_dtm_buffer\" and calcualted \"dist\" to buffer_all_df \n",
    "# add required field \"slope\" to buffer_all_df \n",
    "# buffer_all_df to Buffer_all_shp\n",
    "# list of shapely geometry points\n",
    "buffer_all_geometry = ( \n",
    "    [sp.geometry.Point(row['x_buffer'], row['y_buffer']) for key, row in buffer_all_df.iterrows()] )\n",
    "# create buffer_all_geometry_df\n",
    "buffer_all_geometry_df = gpd.GeoDataFrame(buffer_all_df, geometry=buffer_all_geometry, crs = crs)\n",
    "# write df to Buffer_all_shp\n",
    "buffer_all_geometry_df.to_file(Buffer_all_shp, driver='ESRI Shapefile') \n",
    "# get DTM values for Buffer_all_shp\n",
    "#   write to Buffer_dtm_csv\n",
    "processing.runalg(\"grass7:r.what.points\",DTM,Buffer_all_shp, \"NA\",\",\", 500,True,False,False,False,False,\n",
    "                  grass_region,-1,0.0001,Buffer_dtm_csv)\n",
    "# create buffer_dtm_df (dataframe) from Buffer_dtm_csv\n",
    "buffer_dtm_df = pd.read_csv(Buffer_dtm_csv)\n",
    "# rename col=tmp... to \"z_dtm_buffer\"\n",
    "buffer_dtm_df_col_tmp = [col for col in buffer_dtm_df.columns if 'tmp' in col]\n",
    "if len(buffer_dtm_df_col_tmp) != 1:\n",
    "    print \"Extraction of DTM col=tmp did not work properly for buffer. Please check\"\n",
    "    exit()\n",
    "buffer_dtm_df = buffer_dtm_df.rename(\n",
    "    columns= {buffer_dtm_df_col_tmp[0]: \"z_dtm_buffer\"})\n",
    "# write buffer_dtm_df[\"z_dtm\"] to buffer_all_df[\"z_dtm\"]\n",
    "buffer_all_df[\"z_dtm_buffer\"] = buffer_dtm_df[\"z_dtm_buffer\"]\n",
    "# get slope values for Buffer_all_shp\n",
    "#   write to Buffer_slope_csv\n",
    "processing.runalg(\"grass7:r.what.points\",DTM_slope,Buffer_all_shp, \"NA\",\",\", \n",
    "                  500,True,False,False,False,False,\n",
    "                  grass_region,-1,0.0001,Buffer_slope_csv)\n",
    "# create buffer_dtm_df (dataframe) from Buffer_dtm_csv\n",
    "buffer_slope_df = pd.read_csv(Buffer_slope_csv)\n",
    "# rename col=tmp... to \"z_dtm_buffer\"\n",
    "buffer_slope_df_col_tmp = [col for col in buffer_slope_df.columns if 'tmp' in col]\n",
    "if len(buffer_slope_df_col_tmp) != 1:\n",
    "    print \"Extraction of Slope col=tmp did not work properly for buffer. Please check\"\n",
    "    exit()\n",
    "buffer_slope_df = buffer_slope_df.rename(\n",
    "    columns= {buffer_slope_df_col_tmp[0]: \"slope\"})\n",
    "# write buffer_dtm_df[\"z_dtm\"] to buffer_all_df[\"z_dtm\"]\n",
    "buffer_all_df[\"slope\"] = buffer_slope_df[\"slope\"]\n",
    "# calculate \"dist\" between each buffer point and associated alignment point \n",
    "buffer_all_df[\"dist\"] = (((buffer_all_df[\"x_align\"] - buffer_all_df[\"x_buffer\"])**2 + \n",
    "                         (buffer_all_df[\"y_align\"] - buffer_all_df[\"y_buffer\"]) **2) +\n",
    "                         (buffer_all_df[\"z_dtm_buffer\"] - buffer_all_df[\"z_align\"]) **2) **(0.5)\n",
    "# clean up\n",
    "buffer_all_df = buffer_all_df.drop(columns =[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate minimum distance to terrain in each buffer ring\n",
    "buffer_all_df[\"min_dist\"] = np.nan\n",
    "for n in range(0, len(alignment_stationed_df)):\n",
    "    buffer_all_df_sel = buffer_all_df.loc[(buffer_all_df[\"id_point\"] == n),]\n",
    "    dist_idxmin=buffer_all_df_sel['dist'].idxmin()\n",
    "    buffer_all_df.loc[(buffer_all_df[\"id_buffer_point\"] == dist_idxmin), \"min_dist\"] = \"MIN\"\n",
    "buffer_all_df.to_csv(Buffer_all_csv, header=True, index=False)  #no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate hydraulic confinement safety factor at each station point\n",
    "#   required input data: reference maximum water pressure elevation (static or dynamic ??) \n",
    "buffer_all_df_sel = buffer_all_df.loc[(buffer_all_df[\"min_dist\"] == \"MIN\"),]\n",
    "dist = array(buffer_all_df_sel['dist'])\n",
    "slope = array(buffer_all_df_sel['slope'])\n",
    "z_align = array(buffer_all_df_sel['z_align'])\n",
    "stat_sum = array(buffer_all_df_sel['stat_sum'])\n",
    "stat_sum[0] = 0  #correction for station_stat_sum being for n-1 above (to be fixed above)\n",
    "def hydr_conf_sf(density_rock, max_static_level, z_align, min_dist, slope):\n",
    "  density_water = 9.805\n",
    "  static_head = max_static_level - z_align \n",
    "  sf = (min_dist * density_rock *  cos(slope*pi/180.)) / (static_head * density_water)\n",
    "  return sf\n",
    "FS = hydr_conf_sf(28.0, max_static_water_level, z_align, dist, slope)\n",
    "buffer_all_df_sel[\"FS\"] = np.nan\n",
    "for n in range(0, len(buffer_all_df_sel)):\n",
    "    buffer_all_df_sel.iloc[n, buffer_all_df_sel.columns.get_loc(\"FS\")] = FS[n]\n",
    "buffer_all_df_sel = buffer_all_df_sel.drop(columns =[\"x_align\", \"y_align\", \"min_dist\", \"id_buffer_point\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate hydraulic confinement safety factor at each station point\n",
    "#   required input data: reference maximum water pressure elevation (static or dynamic ??) \n",
    "buffer_all_df_sel = buffer_all_df.loc[(buffer_all_df[\"min_dist\"] == \"MIN\"),]\n",
    "dist = array(buffer_all_df_sel['dist'])\n",
    "slope = array(buffer_all_df_sel['slope'])\n",
    "z_align = array(buffer_all_df_sel['z_align'])\n",
    "stat_sum = array(buffer_all_df_sel['stat_sum'])\n",
    "stat_sum[0] = 0  #correction for station_stat_sum being for n-1 above (to be fixed above)\n",
    "FS = (dist * 28.0 * cos(slope*pi/180.)) / ((637.20 - z_align) * 10)\n",
    "buffer_all_df_sel[\"FS\"] = np.nan\n",
    "for n in range(0, len(buffer_all_df_sel)):\n",
    "    buffer_all_df_sel.iloc[n, buffer_all_df_sel.columns.get_loc(\"FS\")] = FS[n]\n",
    "buffer_all_df_sel = buffer_all_df_sel.drop(columns =[\"x_align\", \"y_align\", \"min_dist\", \"id_buffer_point\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize variables \n",
    "x_data = []\n",
    "y_data = []\n",
    "traces = []\n",
    "annotations = []\n",
    "\n",
    "fs = buffer_all_df_sel['FS'].tolist(),\n",
    "c_fs = []\n",
    "for i in range(len(buffer_all_df_sel.index)):\n",
    "    if fs[0][i] <= 1.4:\n",
    "        c_fs.append('red')\n",
    "    elif 1.4 < fs[0][i] < 1.8:\n",
    "        c_fs.append('yellow')\n",
    "    else:\n",
    "        c_fs.append('green')\n",
    "slope = buffer_all_df_sel['slope'].tolist(),\n",
    "c_slope = []\n",
    "for i in range(len(buffer_all_df_sel.index)):\n",
    "    if slope[0][i] > 30:\n",
    "        c_slope.append('red')\n",
    "    else:\n",
    "        c_slope.append('green')        \n",
    "\n",
    "x_data = [buffer_all_df_sel['dist_stat'].tolist()]\n",
    "y_data = ['hydraulic confinement']\n",
    "\n",
    "for i in range(0, len(x_data[0])):\n",
    "    for xd, yd in zip(x_data, y_data):\n",
    "        traces.append(go.Bar(\n",
    "            x=[xd[i]],\n",
    "            y=[yd],\n",
    "            width = 0.3,\n",
    "            orientation='h',\n",
    "            marker=dict(\n",
    "                color = c_fs[i],\n",
    "            ),\n",
    "            hoverinfo = 'none',\n",
    "        ))\n",
    "        \n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=False,\n",
    "        zeroline=False,\n",
    "        domain=[0.08, 1]  #horizontal extent of bar\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=False,\n",
    "        zeroline=False,\n",
    "    ),\n",
    "    barmode='stack',\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        t=0,\n",
    "        b=0\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    width=945,\n",
    "    height=70,\n",
    ")\n",
    "\n",
    "for yd, xd in zip(y_data, x_data):\n",
    "    # labeling the y-axis\n",
    "    annotations.append(dict(xref='paper', yref='y',\n",
    "                            x=0.09, y=yd, #x is position of text\n",
    "                            xanchor='left',\n",
    "                            text=str(yd),\n",
    "                            font=dict(family='Arial', size=14,\n",
    "                                      color='white'),\n",
    "                            showarrow=False, align='left'))\n",
    "layout['annotations'] = annotations\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layout': {'showlegend': False, 'width': 945, 'yaxis': {'zeroline': False, 'showline': False, 'showticklabels': False, 'showgrid': False}, 'height': 70, 'barmode': 'stack', 'xaxis': {'zeroline': False, 'showline': False, 'domain': [0.08, 1], 'showticklabels': False, 'showgrid': False}, 'margin': {'r': 0, 'b': 0, 't': 0, 'l': 0}, 'annotations': [{'xref': 'paper', 'xanchor': 'left', 'yref': 'y', 'text': 'hydraulic confinement', 'align': 'left', 'y': 'hydraulic confinement', 'x': 0.09, 'font': {'color': 'white', 'family': 'Arial', 'size': 14}, 'showarrow': False}]}, 'data': [{'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [nan], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [41.24006281823614], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [41.24006281823614], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [41.24006281814349], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [41.24006281823614], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372692455], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.765774372590606], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.76577437270338], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259619671], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259639666], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259619671], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [49.58662259613706], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479710773], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479684762], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479710773], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479710773], 'type': 'bar', 'marker': {'color': 'green'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479684762], 'type': 'bar', 'marker': {'color': 'yellow'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479710773], 'type': 'bar', 'marker': {'color': 'red'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479710773], 'type': 'bar', 'marker': {'color': 'red'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479684762], 'type': 'bar', 'marker': {'color': 'red'}}, {'orientation': 'h', 'width': 0.3, 'hoverinfo': 'none', 'y': ['hydraulic confinement'], 'x': [48.00614479710773], 'type': 'bar', 'marker': {'color': 'red'}}]}\n"
     ]
    }
   ],
   "source": [
    "print(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
